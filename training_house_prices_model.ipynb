{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/regression/auto-ml-regression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.57\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "print(azureml.core.VERSION) #should be 1.0.57 or greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "experiment_name = 'house_prices_regression'\n",
    "project_folder = './sample_projects/house_prices_regression'\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "This uses the AzureML datastore and dataset api's, as well as data manipulation, with keep_ and drop_ columns, and random_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrimeRate</th>\n",
       "      <th>ResidentialZoning</th>\n",
       "      <th>IndustrialZoning</th>\n",
       "      <th>OnRiver</th>\n",
       "      <th>NOXConcentration</th>\n",
       "      <th>NumberOfRooms</th>\n",
       "      <th>PreWarHouses</th>\n",
       "      <th>DistanceToEmployment</th>\n",
       "      <th>DistanceToHighways</th>\n",
       "      <th>PropertyTaxRate</th>\n",
       "      <th>ParentTeachRatio</th>\n",
       "      <th>ProportionAA</th>\n",
       "      <th>LowerStatusProportion</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>6.58</td>\n",
       "      <td>65.20</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>296.00</td>\n",
       "      <td>15.30</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>6.42</td>\n",
       "      <td>78.90</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>7.18</td>\n",
       "      <td>61.10</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CrimeRate  ResidentialZoning  IndustrialZoning  OnRiver  NOXConcentration  \\\n",
       "0       0.01              18.00              2.31     0.00              0.54   \n",
       "1       0.03               0.00              7.07     0.00              0.47   \n",
       "2       0.03               0.00              7.07     0.00              0.47   \n",
       "\n",
       "   NumberOfRooms  PreWarHouses  DistanceToEmployment  DistanceToHighways  \\\n",
       "0           6.58         65.20                  4.09                1.00   \n",
       "1           6.42         78.90                  4.97                2.00   \n",
       "2           7.18         61.10                  4.97                2.00   \n",
       "\n",
       "   PropertyTaxRate  ParentTeachRatio  ProportionAA  LowerStatusProportion  \\\n",
       "0           296.00             15.30        396.90                   4.98   \n",
       "1           242.00             17.80        396.90                   9.14   \n",
       "2           242.00             17.80        392.83                   4.03   \n",
       "\n",
       "   Price  \n",
       "0  24.00  \n",
       "1  21.60  \n",
       "2  34.70  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_name = 'edvanstorage__azureml'\n",
    "dataset_path = 'boston_houses/boston_data.csv'\n",
    "datastore = Datastore.get(ws, datastore_name)\n",
    "data_reference = DataReference(datastore, data_reference_name=\"boston_data\", path_on_datastore=dataset_path)\n",
    "boston_ds = Dataset.Tabular.from_delimited_files(data_reference)\n",
    "boston_ds = boston_ds.drop_columns('Column1')\n",
    "boston_ds.take(3).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train, b_test = boston_ds.random_split(0.2, seed=84)\n",
    "X_train = b_train.drop_columns('Price')\n",
    "y_train = b_train.keep_columns('Price')\n",
    "X_test = b_test.drop_columns('Price')\n",
    "y_test = b_test.keep_columns('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote compute\n",
    "Setup the environments for remote compute, we might not need it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target = ws.compute_targets['cpucluster']\n",
    "run_config = RunConfiguration(framework=\"python\")\n",
    "run_config.target = compute_target\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n",
    "\n",
    "dependencies = CondaDependencies.create(\n",
    "    pip_packages=[\"scikit-learn\", \"scipy\", \"numpy\"])\n",
    "run_config.environment.python.conda_dependencies = dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Instantiate an `AutoMLConfig` object to specify the settings for both local and remote runs and data used to run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_config = {\"task\": 'regression',\n",
    "         \"iteration_timeout_minutes\": 10,\n",
    "         \"primary_metric\": 'normalized_root_mean_squared_error',\n",
    "         \"debug_log\": 'automl.log',\n",
    "         \"verbosity\": logging.INFO,\n",
    "         \"enable_early_stopping\": True,\n",
    "         \"X\": X_train, \n",
    "         \"y\": y_train,\n",
    "         \"path\": project_folder}\n",
    "\n",
    "local_run = False\n",
    "if local_run:\n",
    "    numb_run_config = {\n",
    "        'iterations': 10,\n",
    "        'n_cross_validations': 5\n",
    "    }\n",
    "else:\n",
    "    numb_run_config = {\n",
    "        'iterations': 250,\n",
    "        'n_cross_validations': 10\n",
    "    }    \n",
    "    remote_config = {\n",
    "        'compute_target': compute_target,\n",
    "        'run_configuration': run_config,\n",
    "        'max_cores_per_iteration': 2,\n",
    "        'max_concurrent_iterations': 10,\n",
    "    }\n",
    "    aml_config.update(remote_config)\n",
    "aml_config.update(numb_run_config)\n",
    "    \n",
    "automl_config = AutoMLConfig(**aml_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 250 iterations on remote compute (with STANDARD_D2_V2 VM's), with 10-fold cross validation.\n",
      "Not showing output here. Please run the Widget cell below.\n"
     ]
    }
   ],
   "source": [
    "show_run = False\n",
    "if 'compute_target' in aml_config:\n",
    "    print(f\"Running {aml_config['iterations']} iterations on remote compute (with {compute_target.vm_size} VM's), with {aml_config['n_cross_validations']}-fold cross validation.\")\n",
    "else:\n",
    "    print(f\"Running {aml_config['iterations']} iterations on local compute, with {aml_config['n_cross_validations']}-fold cross validation.\")\n",
    "if not show_run:\n",
    "    print(\"Not showing output here. Please run the Widget cell below.\")\n",
    "else:\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "run = experiment.submit(automl_config, show_output = show_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.widgets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3cb5a35b804e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azureml.widgets'"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>house_prices_regression</td><td>AutoML_f21709b6-891f-454f-b677-f0b6b8bb626f</td><td>automl</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/8f962503-0c00-4280-a157-8c20b3a9d990/resourceGroups/azureml/providers/Microsoft.MachineLearningServices/workspaces/azureml_kickstarter/experiments/house_prices_regression/runs/AutoML_f21709b6-891f-454f-b677-f0b6b8bb626f\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: house_prices_regression,\n",
       "Id: AutoML_f21709b6-891f-454f-b677-f0b6b8bb626f,\n",
       "Type: automl,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Retrieve All Child Runs\n",
    "You can also use SDK methods to fetch all the child runs and see individual metrics that we log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = list(run.get_children())\n",
    "metricslist = {}\n",
    "for r in children:\n",
    "    properties = r.get_properties()\n",
    "    metrics = {k: v for k, v in r.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model\n",
    "\n",
    "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(\"----------------------------\")\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model Based on Any Other Metric\n",
    "Show the run and the model that has the smallest `root_mean_squared_error` value (which turned out to be the same as the one with largest `spearman_correlation` value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_metric = \"spearman_correlation\"\n",
    "best_run, fitted_model = run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(\"----------------------------\")\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model from a Specific Iteration\n",
    "Show the run and the model from the third iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 3\n",
    "third_run, third_model = run.get_output(iteration = iteration)\n",
    "print(third_run)\n",
    "print(\"----------------------------\")\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on training and test set, and calculate residual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pd = X_train.to_pandas_dataframe()\n",
    "y_train_pd = y_train.to_pandas_dataframe().squeeze()\n",
    "X_test_pd = X_test.to_pandas_dataframe()\n",
    "y_test_pd = y_test.to_pandas_dataframe().squeeze()\n",
    "\n",
    "y_pred_train = fitted_model.predict(X_train_pd)\n",
    "y_residual_train = y_train_pd - y_pred_train\n",
    "\n",
    "y_pred_test = fitted_model.predict(X_test_pd)\n",
    "y_residual_test = y_test_pd - y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set up a multi-plot chart.\n",
    "f, (a0, a1) = plt.subplots(1, 2, gridspec_kw = {'width_ratios':[1, 1], 'wspace':0, 'hspace': 0})\n",
    "f.suptitle('Regression Residual Values', fontsize = 18)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(16)\n",
    "\n",
    "# Plot residual values of training set.\n",
    "a0.axis([0, 360, -200, 200])\n",
    "a0.plot(y_residual_train, 'bo', alpha = 0.5)\n",
    "a0.plot([-10,360],[0,0], 'r-', lw = 3)\n",
    "a0.text(16,170,'RMSE = {0:.2f}'.format(np.sqrt(mean_squared_error(y_train_pd, y_pred_train))), fontsize = 12)\n",
    "a0.text(16,140,'R2 score = {0:.2f}'.format(r2_score(y_train_pd, y_pred_train)), fontsize = 12)\n",
    "a0.set_xlabel('Training samples', fontsize = 12)\n",
    "a0.set_ylabel('Residual Values', fontsize = 12)\n",
    "\n",
    "# Plot a histogram.\n",
    "a0.hist(y_residual_train, orientation = 'horizontal', color = 'b', bins = 10, histtype = 'step')\n",
    "a0.hist(y_residual_train, orientation = 'horizontal', color = 'b', alpha = 0.2, bins = 10)\n",
    "\n",
    "# Plot residual values of test set.\n",
    "a1.axis([0, 90, -200, 200])\n",
    "a1.plot(y_residual_test, 'bo', alpha = 0.5)\n",
    "a1.plot([-10,360],[0,0], 'r-', lw = 3)\n",
    "a1.text(5,170,'RMSE = {0:.2f}'.format(np.sqrt(mean_squared_error(y_test_pd, y_pred_test))), fontsize = 12)\n",
    "a1.text(5,140,'R2 score = {0:.2f}'.format(r2_score(y_test_pd, y_pred_test)), fontsize = 12)\n",
    "a1.set_xlabel('Test samples', fontsize = 12)\n",
    "a1.set_yticklabels([])\n",
    "\n",
    "# Plot a histogram.\n",
    "a1.hist(y_residual_test, orientation = 'horizontal', color = 'b', bins = 10, histtype = 'step')\n",
    "a1.hist(y_residual_test, orientation = 'horizontal', color = 'b', alpha = 0.2, bins = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse = {}\n",
    "for ite in range(aml_config['iterations']):\n",
    "    i_run, model = run.get_output(iteration = ite)\n",
    "    y_pred_test = model.predict(X_test_pd)\n",
    "    all_rmse[ite] = np.sqrt(mean_squared_error(y_test_pd, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iteration = sorted(all_rmse, key=all_rmse.get, reverse=False)[0]\n",
    "print(f'Best iteration is number {best_iteration}')\n",
    "print(\"--------------\")\n",
    "best_test_run, best_test_model = run.get_output(iteration = best_iteration)\n",
    "print(best_test_run)\n",
    "print(best_test_run.get_file_names())\n",
    "print(\"--------------\")\n",
    "print(best_test_model)\n",
    "# print(best_test_model.get_model_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = run.get_run_sdk_dependencies(iteration = best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['azureml-train-automl', 'azureml-core']:\n",
    "    print('{}\\t{}'.format(p, dependencies[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn','py-xgboost==0.80'], pip_packages=['azureml-train-automl'])\n",
    "\n",
    "conda_env_file_name = 'conda_dependencies.yml'\n",
    "myenv.save_to_file('.', conda_env_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model and commit dependencies and score files first\n",
    "\n",
    "Since the Release is triggered from a new version of the model, first the dependent files are updated in the repo, then the new model is registered, which triggers the release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_changes = !git diff conda_dependencies.yml\n",
    "score_changes = !git diff score.py\n",
    "inference_changes = !git diff inference_config.json\n",
    "aci_config_changes = !git diff aci_deployment_config.json\n",
    "aks_config_changes = !git diff aks_deployment_config.json\n",
    "if len(dep_changes) > 0:\n",
    "    !git add conda_dependencies.yml\n",
    "if len(score_changes) > 0:\n",
    "    !git add score.py\n",
    "if len(inference_changes) > 0:\n",
    "    !git add inference_config.json\n",
    "if len(aci_config_changes) > 0:\n",
    "    !git add aci_deployment_config.json\n",
    "if len(aks_config_changes) > 0:\n",
    "    !git add aks_deployment_config.json\n",
    "if len(dep_changes)+len(score_changes)+len(inference_changes)+len(aci_config_changes)+len(aks_config_changes)>0:\n",
    "    print(\"Changes to commit. Committing and pushing now\")\n",
    "    !git commit -m \"Commit from NB\"\n",
    "    !git push\n",
    "else:\n",
    "    print(\"No changes to commit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"house_prices_regression\"\n",
    "deploy = True\n",
    "\n",
    "# best_test_model.register(ws, )\n",
    "model = best_test_run.register_model(name, model_path='outputs/model.pkl')\n",
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "savitam"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
